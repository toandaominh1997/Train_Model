{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Test(ZALORA).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/toandaominh1997/Train_Model/blob/master/Machine_Learning_Test(ZALORA).ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "0x_fN7BNJltg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa7fb23a-3b42-47bd-fa51-4f1008d1cac4"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8C5o6MMfjPpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c9d449f8-aa40-4f3c-c417-d5744eb92b64"
      },
      "cell_type": "code",
      "source": [
        "# Install library\n",
        "!pip install lightgbm"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uoxz-ChmJoXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vb6_4X3KdXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf0b8487-b681-44a0-edae-fa543ebc32f2"
      },
      "cell_type": "code",
      "source": [
        "!ls \"drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/test_data\" \n",
        "data_dir = \"drive/My Drive/Dataset/Machine Learning Test(ZALORA)/\""
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nornal_comments.txt  sara_comments.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iodmVYJSUc97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bb26d21f-4540-4323-c6d2-02b2cfbb723c"
      },
      "cell_type": "code",
      "source": [
        "def readTxt(filename):\n",
        "  print(filename)\n",
        "  lines = []\n",
        "  with open(filename) as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  return lines\n",
        "\n",
        "normal = readTxt(data_dir+'data/training_data/normal_comments.txt')\n",
        "stop_words = readTxt(data_dir+'data/training_data/normal_comments.txt')\n",
        "sara = readTxt(data_dir+'data/training_data/sara_comments.txt')\n",
        "normal_test= readTxt(data_dir+'data/test_data/nornal_comments.txt')\n",
        "sara_test = readTxt(data_dir+'data/test_data/sara_comments.txt')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/normal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/normal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/training_data/sara_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/test_data/nornal_comments.txt\n",
            "drive/My Drive/Dataset/Machine Learning Test(ZALORA)/data/test_data/sara_comments.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oaz4m5y6K7-v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normal_labels = np.ones((len(normal), 1))\n",
        "sara_labels = np.zeros((len(sara), 1))\n",
        "labels = np.concatenate((normal_labels, sara_labels), axis=0)\n",
        "\n",
        "# Labels of Test Datasets\n",
        "normal_test_labels = np.ones((len(normal_test), 1))\n",
        "sara_test_labels = np.zeros((len(sara_test), 1))\n",
        "labels_test = np.concatenate((normal_test_labels, sara_test_labels), axis=0)\n",
        "\n",
        "normal.extend(sara)\n",
        "normal_test.extend(sara_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzp6MXPjUJeu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer(stop_words=stop_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iphu-4b7ZmDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2526b8fb-f17b-4f52-d58b-63f2ab86fb01"
      },
      "cell_type": "code",
      "source": [
        "vect"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
              "        stop_words=['\\t\\n', \"In sya Allah.....mereka berhasil ubtuk mengubah kehidupan keluarganya. Aamiin yaa rabbal'aalamiin.\\n\", 'Kasian,akibat terpojok,fitnah sana sini,salut tau dri mana si ahoak soal ktua MUI ma SBY,pakek gaya SPY.\\t\\t\\n', 'Allahu Akbar.....hidup FPI\\n', 'pamer\\n', 'Mantap Tegakkan Hu...y yah.\\tSeharian tebar kebencian..ckckckck\\n\", 'Itu bisa jawab kan... Uda santai aja.. \\tCaoowww\\n'],\n",
              "        strip_accents=None, sublinear_tf=False,\n",
              "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "        vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "am5Gi5AwZt9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f09b9c3b-4fd5-4100-da8e-576376f7f23b"
      },
      "cell_type": "code",
      "source": [
        "X_dtm = vect.fit_transform(normal)\n",
        "print(X_dtm.shape)\n",
        "print(labels.shape)\n",
        "test_X_dtm = vect.transform(normal_test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75300, 60207)\n",
            "(75300, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Zqh87LPZ1X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e4bd0285-4339-48ce-aae0-80e30c483bb1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "logreg = LogisticRegression(C=12.0)\n",
        "\n",
        "logreg.fit(X_dtm, labels)\n",
        "y_pred_X = logreg.predict(X_dtm)\n",
        "print('Training accuracy is {}'.format(accuracy_score(labels, y_pred_X)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9385126162018592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogeEh1DkbSTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed953954-818f-4faf-9287-e80b9c86cd56"
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = logreg.predict(test_X_dtm)\n",
        "print('Training accuracy is {}'.format(accuracy_score(labels_test, y_pred_test)))\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.8568318473978851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jxp2lbkxc7cs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "metadata": {
        "id": "8k8ThgeRcoXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "42202217-24ee-4dca-e313-92d95be6c7fa"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "suvm = svm.SVC(gamma='auto')\n",
        "suvm.fit(X_dtm, labels)\n",
        "y_pred_X = suvm.predict(X_dtm)\n",
        "print('Training accuracy is {}'.format(accuracy_score(labels, y_pred_X)))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.8020185922974767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "28Lcbr9zdAT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb088ed4-25d4-4513-e6c8-5a49378f0bd5"
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = suvm.predict(test_X_dtm)\n",
        "print('Training accuracy is {}'.format(accuracy_score(labels_test, y_pred_test)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.7080655193862742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xoA8SWhQg0FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f8090201-136e-4c45-9af1-928ab6e9908d"
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "model = LogisticRegression(solver='sag')\n",
        "sfm = SelectFromModel(model, threshold=0.2)\n",
        "labels = np.asarray(labels)\n",
        "labels = labels.ravel()\n",
        "\n",
        "\n",
        "\n",
        "train_sparse_matrix = sfm.fit_transform(X_dtm, labels)\n",
        "train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, labels, test_size=0.05, random_state=144)\n",
        "\n",
        "test_sparse_matrix = sfm.transform(test_X_dtm)\n",
        "\n",
        "d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
        "d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
        "watchlist = [d_train, d_valid]\n",
        " \n",
        "params = {'learning_rate': 0.2,\n",
        "              'application': 'binary',\n",
        "              'num_leaves': 31,\n",
        "              'verbosity': -1,\n",
        "              'metric': 'auc',\n",
        "              'data_random_seed': 2,\n",
        "              'bagging_fraction': 0.8,\n",
        "              'feature_fraction': 0.6,\n",
        "              'nthread': 4,\n",
        "              'lambda_l1': 1,\n",
        "              'lambda_l2': 1}\n",
        "\n",
        "model = lgb.train(params, train_set=d_train, valid_sets=watchlist, verbose_eval=10)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10]\ttraining's auc: 0.826667\tvalid_1's auc: 0.81408\n",
            "[20]\ttraining's auc: 0.85095\tvalid_1's auc: 0.834444\n",
            "[30]\ttraining's auc: 0.864666\tvalid_1's auc: 0.844904\n",
            "[40]\ttraining's auc: 0.872307\tvalid_1's auc: 0.846819\n",
            "[50]\ttraining's auc: 0.878998\tvalid_1's auc: 0.848382\n",
            "[60]\ttraining's auc: 0.884088\tvalid_1's auc: 0.850282\n",
            "[70]\ttraining's auc: 0.888236\tvalid_1's auc: 0.850574\n",
            "[80]\ttraining's auc: 0.892249\tvalid_1's auc: 0.850342\n",
            "[90]\ttraining's auc: 0.895669\tvalid_1's auc: 0.85059\n",
            "[100]\ttraining's auc: 0.898771\tvalid_1's auc: 0.85246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23BHkMb0jMJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a18af19c-2275-4fd8-ee2b-c759eba3d1ab"
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(test_sparse_matrix)\n",
        "\n",
        "print('Training accuracy is {}'.format(accuracy_score(labels_test, y_pred_test.round())))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.8592162554426706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cDlr2bdznJkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}